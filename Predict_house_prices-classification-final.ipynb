{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will be used to load the dataset and preprocess it\n",
    "class HouseDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, drop_col=None):\n",
    "        super(HouseDataset, self).__init__()\n",
    "        self.image_folder = image_folder\n",
    "        self.drop_col = drop_col\n",
    "\n",
    "        df = self.load_df(csv_file) #load the text file\n",
    "        self.features, self.labels = self.preprocess_data(df) # call the preprocess function to preprocess the data\n",
    "        transform_list = [\n",
    "            transforms.Grayscale(1),\n",
    "            transforms.Resize((64, 64)), \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)) \n",
    "        ] # this is the list of transforms that will be applied to the images\n",
    "        self.transform = transforms.Compose(transform_list)\n",
    "\n",
    "    # this function will load the text file and return a dataframe\n",
    "    def load_df(self, csv_file):\n",
    "        df_list = pd.read_csv(csv_file).values.tolist() # read the text file and convert it to a list\n",
    "        data = [line[0].split(' ') for line in df_list]\n",
    "        for i in range(len(data)):\n",
    "            data[i] = [(float(x) if '.' in x else int(x)) for x in data[i] if x != ''] # convert the string to float or int\n",
    "        df = pd.DataFrame(data, index=range(1, len(data) + 1),\n",
    "                          columns=['Bedrooms', 'Bathrooms', 'Area', 'Zipcode', 'Prices']) # convert the list to a dataframe and add the column names\n",
    "        self.seq_len = df.shape[1]-1 # extract the number of features\n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        # Process the Zipcode and Prices\n",
    "        # get the unique zipcodes to then map them to a number by order then replace the zipcode column with the new numbers\n",
    "        zipcode_unique = df['Zipcode'].unique()\n",
    "        zipcode_dict = dict(zip(zipcode_unique, range(len(zipcode_unique))))\n",
    "        df['Zipcode'] = df['Zipcode'].map(zipcode_dict)\n",
    "        \n",
    "        # get the unique prices to then make a list of boundaries to categorize the prices then replace the prices column with the new categories\n",
    "        df['Prices'] = df['Prices'] / 100000\n",
    "        prices_boundaries = list(np.arange(int(min(df['Prices'])), int(max(df['Prices'])), 10))\n",
    "        prices_boundaries.append(np.inf)\n",
    "        labels = list(range(len(prices_boundaries) - 1))\n",
    "        df['PriceCategory'] = pd.cut(df['Prices'], bins=prices_boundaries, labels=labels, include_lowest=True) \n",
    "        \n",
    "        # Splitting the features and labels\n",
    "        features = df.drop('PriceCategory', axis=1).drop('Prices', axis=1)\n",
    "        if self.drop_col: \n",
    "            features = features.drop(self.drop_col, axis=1) # this will drop the column that is passed in the constructor\n",
    "        labels = torch.tensor(df['PriceCategory'].values, dtype=torch.long)\n",
    "        \n",
    "        # Standardize the features so we make sure that all the features are in the same range  (mean = 0, std = 1)\n",
    "        scaler = StandardScaler()\n",
    "        features = pd.DataFrame(scaler.fit_transform(features), columns=features.columns)\n",
    "\n",
    "        return features, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Getting images\n",
    "        image_names = [f\"{idx+1}_bathroom.jpg\", f\"{idx+1}_bedroom.jpg\", f\"{idx+1}_frontal.jpg\", f\"{idx+1}_kitchen.jpg\"]\n",
    "        images = [Image.open(f\"{self.image_folder}/{name}\") for name in image_names]\n",
    "        images = [self.transform(image) for image in images]\n",
    "        images = [torch.tensor(image) for image in images]\n",
    "        # Getting textual features\n",
    "        textual_data = torch.tensor(self.features.iloc[idx].values, dtype=torch.float32)\n",
    "        textual_features = torch.tensor(textual_data)\n",
    "        # Getting labels\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return images, textual_features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the dataset\n",
    "# NOTE: uncomment the dataset which excludes the column that you want to drop\n",
    "all_dataset = HouseDataset(csv_file='Data/HousesInfo.txt', image_folder='Data/Dataset')\n",
    "# drop_zc = HouseDataset(csv_file='Data/HousesInfo.txt', image_folder='Data/Dataset', drop_col='Zipcode')\n",
    "# drop_rn = HouseDataset(csv_file='Data/HousesInfo.txt', image_folder='Data/Dataset', drop_col='Bedrooms')\n",
    "# drop_ba = HouseDataset(csv_file='Data/HousesInfo.txt', image_folder='Data/Dataset', drop_col='Bathrooms')\n",
    "# drop_ar = HouseDataset(csv_file='Data/HousesInfo.txt', image_folder='Data/Dataset', drop_col='Area')\n",
    "\n",
    "# pass the dataset you chose to the main dataset parameter which will then be used in the dataloader\n",
    "dataset=all_dataset\n",
    "# dataset=drop_zc\n",
    "# dataset=drop_rn\n",
    "# dataset=drop_ba\n",
    "# dataset=drop_ar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation and test and create the dataloaders\n",
    "\n",
    "def split_data(dataset, batch_size=32):\n",
    "    # Define the size of each split of each dataset\n",
    "    train_split = int(0.65*len(dataset))\n",
    "    test_split = int(0.2*len(dataset))\n",
    "    val_split = len(dataset) - train_split - test_split\n",
    "    # Use the random_split function to split dataset into non-overlapping datasets of the given lengths\n",
    "    train_data, val_data, test_data = random_split(dataset, [train_split, val_split, test_split])\n",
    "    \n",
    "    # Create the dataloaders \n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True) # we shuffle the training data to make sure batches will be different in each epoch\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = split_data(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will be used to train the model on images only\n",
    "class MultiImgsCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiImgsCNN, self).__init__()\n",
    "        # Define partitions, each with a convolutional layer and a ReLU activation function\n",
    "        self.partition1 = nn.Sequential(nn.Conv2d(1, 128, kernel_size=3, padding=1), nn.ReLU()) \n",
    "        self.partition2 = nn.Sequential(nn.Conv2d(1, 128, kernel_size=3, padding=1), nn.ReLU())\n",
    "        self.partition3 = nn.Sequential(nn.Conv2d(1, 128, kernel_size=3, padding=1), nn.ReLU())\n",
    "        self.partition4 = nn.Sequential(nn.Conv2d(1, 128, kernel_size=3, padding=1), nn.ReLU())\n",
    "        # passing each image through its partition helps to extract features from each image separately to make sure \n",
    "        \n",
    "        # Define layers after combining the partitions\n",
    "        self.combined_conv = nn.Sequential(nn.Conv2d(512, 256, kernel_size=3, padding=1),   # Example layer\n",
    "        nn.MaxPool2d(kernel_size=2), \n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "        nn.MaxPool2d(kernel_size=2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(), #flatten the output of the previous layer to be able to pass it to the linear layer\n",
    "        )\n",
    "        self.fc = nn.Linear(128 * 16 * 16, 128)  # Adjust dimensions as necessary to match the input of next layer\n",
    "\n",
    "    def forward(self, l):\n",
    "        # Pass each image through its partition\n",
    "        out1 = self.partition1(l[0])\n",
    "        out2 = self.partition2(l[1])\n",
    "        out3 = self.partition1(l[2])\n",
    "        out4 = self.partition2(l[3])\n",
    "    \n",
    "        # Combine the outputs\n",
    "        cnn_combined = torch.cat((out1, out2, out3, out4), 1)  # Concatenate along the channel dimension\n",
    "        # Pass through the other layers\n",
    "        cnn_combined = self.combined_conv(cnn_combined)\n",
    "        cnn_combined = cnn_combined.view(cnn_combined.size(0), -1)  # Flatten the output of the previous layer to be able to pass it to the linear layer\n",
    "        cnn_combined = self.fc(cnn_combined)\n",
    "        \n",
    "        return cnn_combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will be used to train the model on tabular(textual) features only\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True) #number of features, number of hidden units, number of layers\n",
    "        self.fc_lstm = nn.Linear(hidden_size, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, textual_features):\n",
    "        # Process textual features \n",
    "        lstm_out, _ = self.lstm(textual_features) \n",
    "        lstm_out = self.fc_lstm(lstm_out)\n",
    "        lstm_out = self.relu(lstm_out)\n",
    "        \n",
    "        return lstm_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class will be used to combine the output of the previous two models\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.images_layer = MultiImgsCNN()\n",
    "        self.features_layer = LSTMModel(input_size=4, hidden_size=32, num_layers=2) # uncomment this when dropping the a column in the features df\n",
    "        # self.features_layer = LSTMModel(input_size=3, hidden_size=32, num_layers=2) # uncomment this when dropping the a column in the features df\n",
    "        \n",
    "        # self.classifier = nn.Sequential(nn.Linear(128 + 128, 6)) # uncomment this when concatenating the output of the two models\n",
    "        self.classifier = nn.Sequential(nn.Linear(128, 6)) # uncomment this when multiplying the output of the two models\n",
    "    \n",
    "    def forward(self, images, textual_features):\n",
    "        image_model = self.images_layer(images)\n",
    "        features_model = self.features_layer(textual_features)\n",
    "        # x = torch.cat((image_model, features_model), dim=1) # uncomment this when concatenating the output of the two models\n",
    "        x = image_model * features_model # uncomment this when multiplying the output of the two models\n",
    "        # x = image_model + features_model # uncomment this when adding the output of the two models\n",
    "        x = self.classifier(x) # pass the output of the two models to the classifier\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to validate the model on the validation set and save the model with the best accuracy\n",
    "def validate(model, val_loader, name):\n",
    "    \n",
    "    '''\n",
    "    validation loop\n",
    "    - check intermediate model performance\n",
    "    - prints accuracy, returns accuracy\n",
    "    '''\n",
    "    \n",
    "    val_loop = tqdm(val_loader, total = len(val_loader), leave = True) \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    \n",
    "    # set the model for validation, gradients are NOT updated\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for x, y, z in val_loop:\n",
    "            x = [tensor.to(device) for tensor in x]\n",
    "            y = y.to(device=device)\n",
    "            z = z.to(device=device)\n",
    "            \n",
    "            scores = model(x, y)\n",
    "            # scores = model(x) # uncomment this when training on images only\n",
    "            # scores = model(y) # uncomment this when training on tabular features only\n",
    "            \n",
    "            predictions = torch.argmax(scores, dim=1)\n",
    "            num_correct += (predictions == z).sum() # calculate the number of correct predictions\n",
    "            num_samples += predictions.size(0) # calculate the number of samples\n",
    "            \n",
    "     \n",
    "    model.train() # set the model back to train mode \n",
    "    \n",
    "    # save model\n",
    "    PATH = f'{name}.pth'\n",
    "    torch.save(model.state_dict(), PATH) \n",
    "    print('The model is saved!')\n",
    "    \n",
    "    \n",
    "    return f'{float(num_correct)/float(num_samples)*100:.2f}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will be used to train the model\n",
    "def train(model, criterion, optimizer, train_loader, validation_loader, num_epochs, name):\n",
    "    \n",
    "    '''\n",
    "    training loop\n",
    "    '''\n",
    "    \n",
    "    # set the model for training (with the gradient updates)\n",
    "    model.train()\n",
    "    \n",
    "    # train for N epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        loop = tqdm(train_loader, total = len(train_loader), leave = True) # progress bar for training loop\n",
    "        \n",
    "        # perform validation every 2 epochs \n",
    "        if epoch % 2 == 0 and epoch != 0:\n",
    "            val_acc = validate(model, validation_loader, name)\n",
    "        else:\n",
    "            val_acc = 0\n",
    "            \n",
    "        for imgs, features, labels in loop:\n",
    "                \n",
    "            imgs = [img.to(device) for img in imgs]\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "                        \n",
    "            outputs = model(imgs, features)\n",
    "            # outputs = model(imgs) # uncomment this when training on images only\n",
    "            # outputs = model(features) # uncomment this when training on tabular features only\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if val_acc != 0:\n",
    "                loop.set_description(f'Epoch [{epoch+1}/{num_epochs}] validation_accuracy = {val_acc}') \n",
    "            else:\n",
    "                loop.set_description(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            loop.set_postfix(loss = loss.item())\n",
    "            \n",
    "    print('Finished training!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy, precision, recall, f1 score for the test \n",
    "def test_model(model, loader):\n",
    "    model.eval()\n",
    "    test_accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    with torch.no_grad():\n",
    "        for img, features, labels in loader:\n",
    "            img = [tensor.to(device) for tensor in img]\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(img, features)\n",
    "        \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            # test_accuracy += accuracy(preds, labels)\n",
    "            \n",
    "            test_accuracy += accuracy_score(labels.cpu(), preds.cpu()) # we add the accuracy of each batch to the total accuracy to get the accuracy of the whole test set by\n",
    "            precision += precision_score(labels.cpu(), preds.cpu(), average='macro')\n",
    "            recall += recall_score(labels.cpu(), preds.cpu(), average='macro')\n",
    "            f1 += f1_score(labels.cpu(), preds.cpu(), average='macro')\n",
    "            \n",
    "    print(f'Test Accuracy: {test_accuracy/len(test_loader)*100:.4f}% \\n Test Precision: {precision/len(test_loader)*100:.4f}%, \\n Test Recall: {recall/len(test_loader)*100:.4f}% \\n Test F1 Score: {f1/len(test_loader)*100:.4f}%')\n",
    "    \n",
    "    return test_accuracy/len(test_loader), precision/len(test_loader), recall/len(test_loader), f1/len(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_444835/2611406102.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_444835/2611406102.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_444835/2611406102.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_444835/2611406102.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/tmp/ipykernel_444835/2611406102.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_444835/2611406102.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.6250% \n",
      " Test Precision: 71.3281%, \n",
      " Test Recall: 66.6667% \n",
      " Test F1 Score: 66.7960%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_444835/2611406102.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_444835/2611406102.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_mul = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_mul.parameters(), lr=0.003)\n",
    "epochs = 30\n",
    "train(model_mul, criterion, optimizer, train_loader, val_loader, epochs, 'houses_mul')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/tmp/ipykernel_565101/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_565101/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "Epoch [1/30]: 100%|██████████| 11/11 [00:08<00:00,  1.24it/s, loss=0]   \n",
      "Epoch [2/30]: 100%|██████████| 11/11 [00:07<00:00,  1.41it/s, loss=0]  \n",
      "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:10<00:00,  1.04it/s, loss=0]   \n",
      "Epoch [4/30]: 100%|██████████| 11/11 [00:07<00:00,  1.42it/s, loss=5.71]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] validation_accuracy = 9.09: 100%|██████████| 11/11 [00:10<00:00,  1.05it/s, loss=31] \n",
      "Epoch [6/30]: 100%|██████████| 11/11 [00:07<00:00,  1.39it/s, loss=47]  \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:10<00:00,  1.04it/s, loss=12]  \n",
      "Epoch [8/30]: 100%|██████████| 11/11 [00:07<00:00,  1.39it/s, loss=39.6]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=2.22]\n",
      "Epoch [10/30]: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, loss=2.66]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/30] validation_accuracy = 61.04: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=7.73]\n",
      "Epoch [12/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0]    \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=3.65]\n",
      "Epoch [14/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.00521]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/30] validation_accuracy = 77.92: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=4.67]\n",
      "Epoch [16/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=3.51]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/30] validation_accuracy = 23.38: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=0]   \n",
      "Epoch [18/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=17.3]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=1.21]\n",
      "Epoch [20/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.687]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/30] validation_accuracy = 87.01: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=0.000178]\n",
      "Epoch [22/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.386] \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/30] validation_accuracy = 85.71: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=3.54] \n",
      "Epoch [24/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.00145]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/30] validation_accuracy = 88.31: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=0.0313]\n",
      "Epoch [26/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.0369]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] validation_accuracy = 85.71: 100%|██████████| 11/11 [00:10<00:00,  1.07it/s, loss=0.0143]\n",
      "Epoch [28/30]: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, loss=0.069] \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, loss=2.51]   \n",
      "Epoch [30/30]: 100%|██████████| 11/11 [00:07<00:00,  1.43it/s, loss=0.279] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_imgs = MultiImgsCNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_imgs.parameters(), lr=0.003)\n",
    "epochs = 30\n",
    "train(model_imgs, criterion, optimizer, train_loader, val_loader, epochs, 'houses_imgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_565101/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_565101/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_565101/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_565101/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/tmp/ipykernel_565101/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_565101/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 37.5000% \n",
      " Test Precision: 27.2240%, \n",
      " Test Recall: 28.7054% \n",
      " Test F1 Score: 22.9342%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_565101/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_565101/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    }
   ],
   "source": [
    "acc_imgs, prec_imgs, rec_imgs, f1_imgs = test_model(model_imgs, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/tmp/ipykernel_566259/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_566259/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "Epoch [1/30]: 100%|██████████| 11/11 [00:08<00:00,  1.36it/s, loss=4.81]\n",
      "Epoch [2/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=4.53]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/30] validation_accuracy = 7.79: 100%|██████████| 11/11 [00:09<00:00,  1.17it/s, loss=4.26]\n",
      "Epoch [4/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=4.32]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/30] validation_accuracy = 7.79: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=4.91]\n",
      "Epoch [6/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=4.47]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/30] validation_accuracy = 7.79: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=4.91]\n",
      "Epoch [8/30]: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, loss=4.39]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/30] validation_accuracy = 7.79: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=4.94]\n",
      "Epoch [10/30]: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, loss=3.73]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/30] validation_accuracy = 72.73: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=1.97]\n",
      "Epoch [12/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=1.3]  \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/30] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.645]\n",
      "Epoch [14/30]: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, loss=0.83] \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.425]\n",
      "Epoch [16/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.331]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.586]\n",
      "Epoch [18/30]: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, loss=0.295]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.25] \n",
      "Epoch [20/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.815]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.259]\n",
      "Epoch [22/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.179]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.16] \n",
      "Epoch [24/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=0.65] \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.331]\n",
      "Epoch [26/30]: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, loss=0.139]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.128]\n",
      "Epoch [28/30]: 100%|██████████| 11/11 [00:07<00:00,  1.44it/s, loss=1.69] \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/30] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:09<00:00,  1.17it/s, loss=0.197]\n",
      "Epoch [30/30]: 100%|██████████| 11/11 [00:07<00:00,  1.45it/s, loss=0.0979]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_feat = LSTMModel(input_size=4, hidden_size=32, num_layers=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_feat.parameters(), lr=0.003)\n",
    "epochs = 30\n",
    "train(model_feat, criterion, optimizer, train_loader, val_loader, epochs, 'houses_feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_566259/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_566259/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_566259/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_566259/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_566259/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_566259/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 87.5000% \n",
      " Test Precision: 56.2500%, \n",
      " Test Recall: 62.5000% \n",
      " Test F1 Score: 59.0476%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gussarayo@GU.GU.SE/.venv/lib64/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_566259/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_566259/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    }
   ],
   "source": [
    "acc_feat, prec_feat, rec_feat, f1_feat = test_model(model_feat, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11 [00:00<?, ?it/s]/tmp/ipykernel_596068/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_596068/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "Epoch [1/60]: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it, loss=2]    \n",
      "Epoch [2/60]: 100%|██████████| 11/11 [00:09<00:00,  1.12it/s, loss=0.929]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it, loss=0.213]\n",
      "Epoch [4/60]: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=0.118]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it, loss=1.64] \n",
      "Epoch [6/60]: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it, loss=0.691]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it, loss=0.324]\n",
      "Epoch [8/60]: 100%|██████████| 11/11 [00:10<00:00,  1.03it/s, loss=0.0391]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=0.323]\n",
      "Epoch [10/60]: 100%|██████████| 11/11 [00:09<00:00,  1.12it/s, loss=0.198]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11/60] validation_accuracy = 93.51: 100%|██████████| 11/11 [00:11<00:00,  1.09s/it, loss=0.157]\n",
      "Epoch [12/60]: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=1.24] \n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:12<00:00,  1.16s/it, loss=0.243]\n",
      "Epoch [14/60]: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=0.275]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15/60] validation_accuracy = 94.81: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it, loss=0.0723]\n",
      "Epoch [16/60]: 100%|██████████| 11/11 [00:13<00:00,  1.25s/it, loss=0.412]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:14<00:00,  1.34s/it, loss=0.155]\n",
      "Epoch [18/60]: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it, loss=0.115]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19/60] validation_accuracy = 93.51: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it, loss=0.412]\n",
      "Epoch [20/60]: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=0.143]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21/60] validation_accuracy = 94.81: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it, loss=0.415]\n",
      "Epoch [22/60]: 100%|██████████| 11/11 [00:10<00:00,  1.05it/s, loss=0.114]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23/60] validation_accuracy = 94.81: 100%|██████████| 11/11 [00:12<00:00,  1.10s/it, loss=0.0898]\n",
      "Epoch [24/60]: 100%|██████████| 11/11 [00:12<00:00,  1.10s/it, loss=0.169]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it, loss=0.385]\n",
      "Epoch [26/60]: 100%|██████████| 11/11 [00:10<00:00,  1.03it/s, loss=0.382]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27/60] validation_accuracy = 94.81: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it, loss=0.124]\n",
      "Epoch [28/60]: 100%|██████████| 11/11 [00:09<00:00,  1.11it/s, loss=0.119]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29/60] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it, loss=0.407]\n",
      "Epoch [30/60]: 100%|██████████| 11/11 [00:09<00:00,  1.11it/s, loss=0.17] \n",
      "100%|██████████| 3/3 [00:01<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31/60] validation_accuracy = 89.61: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it, loss=0.0614]\n",
      "Epoch [32/60]: 100%|██████████| 11/11 [00:09<00:00,  1.18it/s, loss=0.106]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33/60] validation_accuracy = 87.01: 100%|██████████| 11/11 [00:12<00:00,  1.16s/it, loss=0.0656]\n",
      "Epoch [34/60]: 100%|██████████| 11/11 [00:11<00:00,  1.00s/it, loss=0.0169]\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35/60] validation_accuracy = 88.31: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it, loss=0.00435]\n",
      "Epoch [36/60]: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=0.00369]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37/60] validation_accuracy = 87.01: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it, loss=0.00358]\n",
      "Epoch [38/60]: 100%|██████████| 11/11 [00:09<00:00,  1.10it/s, loss=0.00576]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39/60] validation_accuracy = 81.82: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it, loss=1.55e-5]\n",
      "Epoch [40/60]: 100%|██████████| 11/11 [00:09<00:00,  1.17it/s, loss=1.5e-5] \n",
      "100%|██████████| 3/3 [00:02<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41/60] validation_accuracy = 90.91: 100%|██████████| 11/11 [00:13<00:00,  1.25s/it, loss=0.0011]  \n",
      "Epoch [42/60]: 100%|██████████| 11/11 [00:10<00:00,  1.00it/s, loss=0.00509]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it, loss=0.000411]\n",
      "Epoch [44/60]: 100%|██████████| 11/11 [00:10<00:00,  1.05it/s, loss=5.13e-6] \n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=8.61e-5]\n",
      "Epoch [46/60]: 100%|██████████| 11/11 [00:10<00:00,  1.09it/s, loss=4.7e-5] \n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it, loss=4.7e-5] \n",
      "Epoch [48/60]: 100%|██████████| 11/11 [00:10<00:00,  1.03it/s, loss=3.1e-5]  \n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.06s/it, loss=0.000201]\n",
      "Epoch [50/60]: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s, loss=0.000105]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.07s/it, loss=2.24e-5]\n",
      "Epoch [52/60]: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=3.35e-5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.04s/it, loss=5.94e-5]\n",
      "Epoch [54/60]: 100%|██████████| 11/11 [00:10<00:00,  1.06it/s, loss=1.35e-5]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:11<00:00,  1.05s/it, loss=1.37e-6]\n",
      "Epoch [56/60]: 100%|██████████| 11/11 [00:10<00:00,  1.08it/s, loss=5.96e-8]\n",
      "100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:12<00:00,  1.09s/it, loss=5.11e-6]\n",
      "Epoch [58/60]: 100%|██████████| 11/11 [00:09<00:00,  1.13it/s, loss=1.51e-6]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model is saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59/60] validation_accuracy = 92.21: 100%|██████████| 11/11 [00:16<00:00,  1.47s/it, loss=2.19e-7]\n",
      "Epoch [60/60]: 100%|██████████| 11/11 [00:09<00:00,  1.15it/s, loss=2.11e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_60 = Model().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_60.parameters(), lr=0.003)\n",
    "epochs = 60\n",
    "train(model_60, criterion, optimizer, train_loader, val_loader, epochs, 'houses_60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_596068/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_596068/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_596068/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_596068/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n",
      "/tmp/ipykernel_596068/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_596068/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.1875% \n",
      " Test Precision: 86.1925%, \n",
      " Test Recall: 80.7229% \n",
      " Test F1 Score: 81.8941%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_596068/990838682.py:65: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  images = [torch.tensor(image) for image in images]\n",
      "/tmp/ipykernel_596068/990838682.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  textual_features = torch.tensor(textual_data)\n"
     ]
    }
   ],
   "source": [
    "acc_60, prec_60, rec_60, f1_60 = test_model(model_60, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
